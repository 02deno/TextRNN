{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NazFiG77SZtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks(RNN)"
      ],
      "metadata": {
        "id": "VZJzo618S7k_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "ktR3A9qDSc3x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKDLeSa4SD4A"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# for network :\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation \n",
        "# Long Short Term Memory(recurrent layer with memory), memory our models\n",
        "# Dense for hidden layers\n",
        "# Activation layer for the output layer\n",
        "\n",
        "# for compiling\n",
        "from keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "cZIqwxinT486"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding = 'utf-8').lower() \n",
        "# rb = read binary"
      ],
      "metadata": {
        "id": "2SJZoxKcT5Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert this text into a numerical format  \n",
        "NN cannot work with sentences. We can pass a numpy array into our network and say predict the next character."
      ],
      "metadata": {
        "id": "l8yNTGouVHFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZgyHzFppNKl",
        "outputId": "08559a98-11c3-4ae2-cd63-740543afd95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)-500001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEXgLlXkxmuA",
        "outputId": "7a50b650-c1e5-4908-9e0b-a062a4fa930c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "615393"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset is too big, selecting only a part of this dataset to train our model\n",
        "# instead of using the whole text\n",
        "start = random.randint(0, len(text)-500001)\n",
        "print(start)\n",
        "text = text[start:start + 500000]\n",
        "#text = text[300000:start + 800000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvS1zWNuVHQQ",
        "outputId": "8da941a2-3648-45e5-b307-e434a8b93509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "414904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set of all the characters in the set\n",
        "characters = sorted(set(text))\n",
        "characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNbbLdOSWwQ5",
        "outputId": "c83ba622-c2c3-4896-af57-2a6cd0db6ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '$',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '3',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c : character - key\n",
        "# i : index - value\n",
        "# enumerate : assigns one number to each character in this set\n",
        "char_to_index = dict((c, i)for i, c in enumerate(characters))\n",
        "char_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2lfJhqLW-nt",
        "outputId": "e248e416-134a-40b3-8b37-72573445d348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'a': 13,\n",
              " 'b': 14,\n",
              " 'c': 15,\n",
              " 'd': 16,\n",
              " 'e': 17,\n",
              " 'f': 18,\n",
              " 'g': 19,\n",
              " 'h': 20,\n",
              " 'i': 21,\n",
              " 'j': 22,\n",
              " 'k': 23,\n",
              " 'l': 24,\n",
              " 'm': 25,\n",
              " 'n': 26,\n",
              " 'o': 27,\n",
              " 'p': 28,\n",
              " 'q': 29,\n",
              " 'r': 30,\n",
              " 's': 31,\n",
              " 't': 32,\n",
              " 'u': 33,\n",
              " 'v': 34,\n",
              " 'w': 35,\n",
              " 'x': 36,\n",
              " 'y': 37,\n",
              " 'z': 38}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the other way around\n",
        "index_to_char = dict((i, c)for i, c in enumerate(characters))\n",
        "index_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYGMoy_mW-qY",
        "outputId": "60e91f9d-078e-4ea8-94ee-52e48592d026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '$',\n",
              " 4: '&',\n",
              " 5: \"'\",\n",
              " 6: ',',\n",
              " 7: '-',\n",
              " 8: '.',\n",
              " 9: '3',\n",
              " 10: ':',\n",
              " 11: ';',\n",
              " 12: '?',\n",
              " 13: 'a',\n",
              " 14: 'b',\n",
              " 15: 'c',\n",
              " 16: 'd',\n",
              " 17: 'e',\n",
              " 18: 'f',\n",
              " 19: 'g',\n",
              " 20: 'h',\n",
              " 21: 'i',\n",
              " 22: 'j',\n",
              " 23: 'k',\n",
              " 24: 'l',\n",
              " 25: 'm',\n",
              " 26: 'n',\n",
              " 27: 'o',\n",
              " 28: 'p',\n",
              " 29: 'q',\n",
              " 30: 'r',\n",
              " 31: 's',\n",
              " 32: 't',\n",
              " 33: 'u',\n",
              " 34: 'v',\n",
              " 35: 'w',\n",
              " 36: 'x',\n",
              " 37: 'y',\n",
              " 38: 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Data"
      ],
      "metadata": {
        "id": "Wi5zSuEnaWBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For example, if the sentence is 'how are yo'\n",
        "# the next character would be a 'u\n",
        "\n",
        "# how many letters or characters are we \n",
        "# gonna use as features or feature data in order to\n",
        "# predict the next character?\n",
        "\n",
        "# you can say predict the next character based on\n",
        "# the last 5 or 500 characters\n",
        "\n",
        "# Gleichgewicht, Balance\n",
        "# careful : network shouldnt be relying on too much data\n",
        "# but you also need to end up with a reasonable text\n",
        "\n",
        "SEQ_LENGTH = 40 \n",
        "STEP_SIZE = 3 \n",
        "# how many characters are we going \n",
        "# to shift to the next sentence \n",
        "# SEQ_LENGTH = 5\n",
        "# Text : Hello World\n",
        "# First Sequence : Hello\n",
        "# After shifting 3 characters\n",
        "# Second Sequnce : lo wo\n",
        "\n",
        "sentences = [] # features\n",
        "next_characters = [] # targets\n"
      ],
      "metadata": {
        "id": "9DydMLlxW-yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "  # i : sequencelerin başlangıç konumları\n",
        "  sentences.append(text[i:i+SEQ_LENGTH]) \n",
        "  next_characters.append(text[i+SEQ_LENGTH]) # always the next correct letter of the sentences\n",
        "sentences[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtYCca7W-0i",
        "outputId": "57d3c73d-e474-42e5-ec89-960b3d3e6c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"t's myself.\\ngive me the glass, and there\",\n",
              " ' myself.\\ngive me the glass, and therein ',\n",
              " 'self.\\ngive me the glass, and therein wil',\n",
              " 'f.\\ngive me the glass, and therein will i',\n",
              " 'give me the glass, and therein will i re']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_characters[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmptW1GNW-3H",
        "outputId": "ff91cccb-00fd-466c-ae88-a79358f91dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'w', 'l', ' ', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the training data into numpy array (numerical format)"
      ],
      "metadata": {
        "id": "roPeB9KCeYuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One dimension for all the possible sentences\n",
        "# One dimension for all the individual positions in these sentences\n",
        "# One dimesion for all the possible characters\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype = np.bool)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED2SHUkSeZED",
        "outputId": "b6719f5f-6759-49db-f20c-6f57b0385286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target data\n",
        "# which would be the next character for which sentence\n",
        "y = np.zeros((len(sentences), len(characters)), dtype = np.bool)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knD8MZigeZLP",
        "outputId": "780a1a9b-ba0d-4ecd-f93c-0fa186519bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences) : # i : index of sentence\n",
        "  for t, character in enumerate(sentence): # t : index of character\n",
        "    x[i, t, char_to_index[character]] = 1 # that char occurs at that position in that sentence -->true\n",
        "  y[i, char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "zYeSoP-mgekJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHJuUDfDh6rJ",
        "outputId": "ba502364-5f2e-47bb-cf53-e633f10687f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       [[False,  True, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False,  True, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False,  True, False, ..., False, False, False]],\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False,  True, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False,  True, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]],\n",
              "\n",
              "       [[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False,  True, False, ..., False, False, False]],\n",
              "\n",
              "       [[ True, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqMoC5GBiBAD",
        "outputId": "33b8b121-a438-4f01-de05-4b2e0a14f39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Network\n",
        "Feed the training data into a RNN so it can predict the next character"
      ],
      "metadata": {
        "id": "pIdocDTMhypK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# first layer : memory, input\n",
        "# memory of our network : it will remember the past couple of\n",
        "# characters, the important and relevant ones\n",
        "# remember the input data, that fed into network few iterations ago\n",
        "# LSTM(#Neurons, input_shape)\n",
        "model.add(LSTM(128, input_shape = (SEQ_LENGTH, len(characters))))"
      ],
      "metadata": {
        "id": "Er_St5uLhyxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# second layer : dense\n",
        "model.add(Dense(len(characters)))"
      ],
      "metadata": {
        "id": "X4r0SV2KiuNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last layer : activation\n",
        "model.add(Activation('softmax'))\n",
        "# softmax : scales the output so that all the values add up to 1\n",
        "# the output is always a probability of how likely a certain character is\n",
        "# going to be the next character\n",
        "\n",
        "# base sequence with multiple characters with a different likelihood\n",
        "# next character : 70% k, 20% x, ..."
      ],
      "metadata": {
        "id": "iWOu0x3dhyzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = learning rate\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVEkvGvehy2H",
        "outputId": "bcb1042c-476a-466f-c9e2-3571babf3af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit it on the training data\n",
        "# batch_size(power of 2) = how many examples are we going to put into the network at once\n",
        "# epochs = how mant times our network is going to see the same data over and over again\n",
        "model.fit(x, y, batch_size =256,epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbwu7dzehy8m",
        "outputId": "4dc9f314-2cf3-48c9-abc5-f7fd69fcb7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 115s 171ms/step - loss: 2.0975\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 126s 193ms/step - loss: 1.6800\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 114s 175ms/step - loss: 1.5667\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 113s 174ms/step - loss: 1.5027\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d3c640fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train once then save them all and later on load them all\n",
        "# instead training over and over again everytime we run the script, requires a lot of time\n",
        "model.save('textgenerator.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8sj2zschy-6",
        "outputId": "5aa7e005-bedb-4b03-b517-2cac5f0c28f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('textgenerator.model')"
      ],
      "metadata": {
        "id": "9l-S3Fprx8Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get predictions and convert these predictions into text generation"
      ],
      "metadata": {
        "id": "t1uruwCnyt8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# takes the predictions of our model\n",
        "# and picks one specific character \n",
        "\n",
        "# this choice will be either conservative\n",
        "# or experimental\n",
        "# high tempature --> risky, experimental, more creative\n",
        "# low tempature --> safe, conservative\n",
        "\n",
        "def sample(preds, tempature = 1.0) :\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / tempature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "gY3CXpwJzA-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, tempature):\n",
        "  start_index = random.randint(0, len(text)- SEQ_LENGTH - 1)\n",
        "  generated = ''\n",
        "  # basis for our text : first 40 characters from original text\n",
        "  sentence = text[start_index : start_index + SEQ_LENGTH]\n",
        "  generated += sentence\n",
        "\n",
        "  for i in range(length):\n",
        "    x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "    for t, character in enumerate(sentence): # index - char\n",
        "      x[0, t, char_to_index[character]] = 1\n",
        "\n",
        "    predictions = model.predict(x, verbose = 0)[0]\n",
        "    next_index = sample(predictions, tempature)\n",
        "    next_character = index_to_char[next_index]\n",
        "\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:] + next_character\n",
        "\n",
        "  return generated"
      ],
      "metadata": {
        "id": "lE6TH2ykzA8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "VJk2iw0m5FPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------0.2--------')\n",
        "print(generate_text(300, 0.2))\n",
        "\n",
        "print('--------0.4--------')\n",
        "print(generate_text(300, 0.4))\n",
        "\n",
        "print('--------0.6--------')\n",
        "print(generate_text(300, 0.6))\n",
        "\n",
        "print('--------0.8--------')\n",
        "print(generate_text(300, 0.8))\n",
        "\n",
        "print('--------1--------')\n",
        "print(generate_text(300, 1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Rfo-UWzA5J",
        "outputId": "1e3baf56-016d-4259-b531-d951ce6c5ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------0.2--------\n",
            "?\n",
            "\n",
            "nurse:\n",
            "marry, that, i think, be young she will be such a courter\n",
            "to the heart to man the sin to the father\n",
            "to conder to promined in the prosent to the hour\n",
            "and the prove to man the pardon to the fire\n",
            "to the dear to the father to the proolans:\n",
            "the senter be the pasion and the father,\n",
            "the thou art to the sun in the pardon to be the sin\n",
            "t\n",
            "--------0.4--------\n",
            "ly she weeps for tybalt's death,\n",
            "and the more of the son and to the father,\n",
            "and the alland the mother and mine of my brother.\n",
            "\n",
            "leontes:\n",
            "now, i thank you pardon in the sword,\n",
            "in some be them to see the gally more him.\n",
            "\n",
            "king edward iv:\n",
            "now the to the heart and from the state it do the house\n",
            "to passon to sire that she gone his solder\n",
            "to many\n",
            "--------0.6--------\n",
            "in the current, made it more\n",
            "violent and bornible him it is dount,\n",
            "to the field and from the pase frem thy sworns,\n",
            "the sorrow what i stall stay, when thy son,\n",
            "to my find with the grave, which is so like.\n",
            "\n",
            "juliet:\n",
            "now then me that mount measure a true merry,\n",
            "what i am some mind i have gentle a fair from one;\n",
            "and we have not the son to good\n",
            "--------0.8--------\n",
            "grindstone and nell.\n",
            "antony, and potpan! and my fault, the fire;\n",
            "givenud my contureful sweet unto the mote\n",
            "to good compery reit on romeo: how, be glied enour,\n",
            "i am sour' forgitiest, our sweft seek prove,\n",
            "sir, for my fangechith and to brother hambing  hand:\n",
            "stand moting soul in that onthings soldo.\n",
            "\n",
            "nurse:\n",
            "why some mething me to news in to\n",
            "--------1--------\n",
            "sabella:\n",
            "my business is a word or two wife we hapne,\n",
            "rind: that elly,' art to fortuness faeft,\n",
            "i midle heart my ta'st forpore that, or you\n",
            "bfemourime! brother shouldsch, of thou shill\n",
            "condur mays trues is these fired, for in\n",
            "thightly, cost free op-shism one. and prayour\n",
            "on with rome, lamps, convigttion all thou.\n",
            "\n",
            "romeo:\n",
            "so till beming is \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGpM39rFzA2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYVg_dXCzAxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}